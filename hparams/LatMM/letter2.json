{
    "Dir": {
        "log_root": "results/letter/k12hc8s2LatMM"
    },
    "Glow" : {
        "image_shape": [4, 4, 1],
        "hidden_channels": 8,
        "K": 12,
        "L": 1,
        "actnorm_scale": 1.0,
        "flow_permutation": "invconv",
        "flow_coupling": "affine",
        "LU_decomposed": false,
        "learn_top": false,
        "y_condition": false,
        "y_classes": 1
    },
    "Mixture" : {
        "naive": false,
        "num_component": 2,
        "regulate_std": true,
        "regulate_mulI": 0,
        "gam_alpha": 2,
        "gam_beta": 1
    },
    "Criterion" : {
        "y_condition": "single-class"
    },
    "Data" : {
        "dataset": "letter",
        "dataset_root": "/home/doli/datasets/letter/separate",
        "num_classes": 26
    },
    "Optim": {
        "name": "adam",
        "args": {
            "lr": 1e-3,
            "betas": [0.9, 0.9999],
            "eps": 1e-8
        },
        "Schedule": {
            "name": "noam_learning_rate_decay",
            "args": {
                "warmup_steps": 1000,
                "minimum": 1e-4
            }
        }
    },
    "Device": {
        "glow": ["cuda:0"],
        "data": "cuda:0"
    },
    "Train": {
        "batch_size": 240,
        "num_batches": 4800,
        "n_epoches": 201,
        "max_grad_clip": 5,
        "max_grad_norm": 100,
        "max_checkpoints": 100,
        "checkpoints_gap": 100,
        "em_gap": 5,
        "num_plot_samples": 1,
        "scalar_log_gap": 50,
        "plot_gap": 50,
        "inference_gap": 50,
        "warm_start": "",
        "weight_y": 0.5
    },
    "Infer": {
        "pre_trained": ""
    }
}
